# Load libraries
library(quantmod)
library(rugarch)
library(PortfolioAnalytics)
library(DEoptim)
library(ROI)
library(tidyverse)


# Set up data
btc <- getSymbols("BTC-USD", src = "yahoo", auto.assign = FALSE)
btc <- Ad(btc)
btc <- to.weekly(btc)
btc <- to.monthly(btc)
btc <- btc["2020-01-01/"]

sp500 <- getSymbols("^GSPC", src = "yahoo", auto.assign = FALSE)
sp500 <- Ad(sp500)
sp500 <- to.weekly(sp500)
sp500 <- to.monthly(sp500)
sp500 <- sp500["2020-01-01/"]


# create a data frame with three columns
# create a data frame with two columns
btc <- data.frame(btc = rnorm(300), date = seq(as.Date("2022-01-01"), by = "day", length.out = 300))
sp500 <- data.frame(sp500 = rnorm(300), date = seq(as.Date("2022-01-01"), by = "day", length.out = 300))
data <- merge.xts(xts(btc[, 1], btc[, 2]), xts(sp500[, 1], sp500[, 2]))


# set column names
colnames(data) <- c("btc", "sp500")

# Merge data
data <- merge(btc, sp500,by="date")
colnames(data) <- c("date","btc", "sp500")

# GARCH model for Bitcoin
# Check for missing values
any(is.na(data))

# Remove missing values
data <- na.omit(data)

# Fit GARCH model
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
                   mean.model = list(armaOrder = c(1, 0)))
garch_fit <- ugarchfit(spec, data$btc, solver = "hybrid")

# Backtesting

# define the length of the rolling window in days
window_length <- 30

# create an empty data frame to store the backtest results
backtest <- data.frame(actual = numeric(0), forecast = numeric(0))

# loop over the rolling windows
for (i in seq(window_length, nrow(data) - window_length + 1, by = 1)) {
  # extract the data for the current window
  window_data <- data[(i - window_length + 1):i, ]
  
  # fit the GARCH model to the current window
  fit <- ugarchfit(spec, window_data[, "btc"], solver = "hybrid")
  
  # forecast the next day's return using the fitted model
  pred <- ugarchforecast(fit, n.ahead = 1)
  
  # store the actual return and the forecasted return in the backtest data frame
  backtest <- rbind(backtest, data.frame(actual = window_data[window_length, "btc"],
                                         forecast = as.numeric(pred@forecast$seriesFor)))
}


# calculate the backtest performance metrics
mse <- mean((backtest$actual - backtest$forecast)^2)
mae <- mean(abs(backtest$actual - backtest$forecast))
rmse <- sqrt(mse)

# print the performance metrics
cat("MSE:", mse, "\n")
cat("MAE:", mae, "\n")
cat("RMSE:", rmse, "\n")


# Pair trading strategy
ratio <- data$btc/data$sp500
zscore <- (ratio - mean(ratio))/sd(ratio)

# Define entry and exit thresholds
entry.threshold <- 2
exit.threshold <- 1

# Compute long and short signals
long.signal <- ifelse(zscore < -entry.threshold, 1, 0)
short.signal <- ifelse(zscore > entry.threshold, 1, 0)

# Compute positions
position <- numeric(length(zscore))
position[1] <- 0

for (i in 2:length(zscore)) {
  if (position[i-1] == 0 & long.signal[i] == 1) {
    position[i] <- 1
  } else if (position[i-1] == 0 & short.signal[i] == 1) {
    position[i] <- -1
  } else if (position[i-1] == 1 & zscore[i] > -exit.threshold) {
    position[i] <- 0
  } else if (position[i-1] == -1 & zscore[i] < exit.threshold) {
    position[i] <- 0
  } else {
    position[i] <- position[i-1]
  }
}

if (length(position) > 0) {
  returns <- c(0, diff(log(ratio))) * position
}else if (is.na(returns) | is.infinite(returns))
  returns <- 0

# Compute performance metrics
sharpe <- mean(returns)/sd(returns)
sortino <- mean(returns[returns < 0])/sd(returns[returns < 0])
max.drawdown <- max(cummax(returns) - returns)/cummax(returns)

# Print performance metrics
cat("Sharpe ratio:", sharpe, "\n")
cat("Sortino ratio:", sortino, "\n")
cat("Maximum drawdown:", max.drawdown, "\n")

# Convert columns to integer type
data[, c(2, 3)] <- lapply(data[, c(2, 3)], as.numeric)
data$date <- as.Date(data$date, format = "%Y-%m-%d")

# Portfolio Optimization
port <- portfolio.spec(assets = c("btc","sp500"))
port <- add.constraint(port, type = "weight_sum", min_sum = 0.99, max_sum = 1.01)
port <- add.constraint(port, type = "box", min = 0.01, max = 0.5)
port <- add.objective(port, type = "return", name = "mean")
port <- add.objective(port, type = "risk", name = "StdDev")
opt <- optimize.portfolio(data, port, optimize_method = "random")

print(opt)



# Compute covariance matrix
cov.mat <- cov(data[,2:3])


# Compute asset returns
returns <- apply(data[,2:3], 2, function(x) {
  ifelse(lag(x) > 0, log(x/lag(x)), NA)
})[-1, ]
colnames(returns) <- colnames(data[,2:3])



# Set up optimization problem
mv_portfolio_weights <- solve.QP(cov.mat, rep(0, ncol(data)),
                                 matrix(1, nrow = 1), 1,
                                 meq = 1)$solution
mv_portfolio_weights <- mv_portfolio_weights/sum(mv_portfolio_weights)

# Compute portfolio returns and volatility
mv_portfolio_return <- sum(colMeans(returns) * mv_portfolio_weights)
mv_portfolio_volatility <- sqrt(t(mv_portfolio_weights) %*% cov.mat %*% mv_portfolio_weights)

# Compute portfolio VaR and CVaR
alpha <- 0.05
mv_portfolio_var <- -qnorm(alpha) * mv_portfolio_volatility * mv_portfolio_return
mv_portfolio_cvar <- -(1/alpha) * (1/sqrt(2*pi)) * exp(-dnorm(qnorm(alpha))/sqrt(2) * mv_portfolio_volatility) * mv_portfolio_return

# Define function to calculate capital required for a given level of risk
calculate_required_capital <- function(return_target, risk_level, alpha, data) {
  
  # Compute covariance matrix
  cov.mat <- cov(data)
  
  # Compute asset weights for minimum variance portfolio
  mv_portfolio_weights <- solve.QP(cov.mat, rep(0, ncol(data)),
                                   matrix(1, nrow = 1), 1,
                                   meq = 1)$solution
  mv_portfolio_weights <- mv_portfolio_weights/sum(mv_portfolio_weights)
  
  # Compute portfolio returns and volatility
  mv_portfolio_return <- sum(colMeans(returns) * mv_portfolio_weights)
  mv_portfolio_volatility <- sqrt(t(mv_portfolio_weights) %*% cov.mat %*% mv_portfolio_weights)
  
  # Compute portfolio VaR and CVaR
  mv_portfolio_var <- -qnorm(alpha) * mv_portfolio_volatility * mv_portfolio_return
  mv_portfolio_cvar <- -(1/alpha) * (1/sqrt(2*pi)) * exp(-dnorm(qnorm(alpha))/sqrt(2) * mv_portfolio_volatility) * mv_portfolio_return
  
  # Calculate required capital
  required_capital <- (risk_level * return_target)/(mv_portfolio_return - mv_portfolio_cvar)
  
  return(required_capital)
}

# Example usage of function
required_capital <- calculate_required_capital(0.05, 1000000, 0.05, data)
print(required_capital)


# calculate the VaR and CVaR of pair trading strategy:


# Compute daily returns
daily_returns <- c(0, diff(log(ratio)))

# Compute VaR and CVaR
var_95 <- quantile(daily_returns, 0.05)
cvar_95 <- mean(daily_returns[daily_returns < var_95])

# Print results
cat("VaR (95%):", round(var_95, 4), "\n")
cat("CVaR (95%):", round(cvar_95, 4), "\n")

# function to set stop-loss limits:

set_stop_loss <- function(data, threshold) {
  # Compute the difference between the two securities
  diff <- data[,1] - data[,2]
  
  # Compute the rolling mean and standard deviation of the difference
  ma <- SMA(diff, n = 20)
  sd <- runSD(diff, n = 20)
  
  # Compute the lower and upper stop-loss limits
  lower <- ma - threshold * sd
  upper <- ma + threshold * sd
  
  # Identify the dates when the difference breaches the stop-loss limits
  breaches <- diff < lower | diff > upper
  
  # Set the stop-loss limits
  stop_loss <- data.frame(lower, upper, breaches)
  
  # Return the stop-loss limits
  return(stop_loss)
}

# Function to calculate the amount of capital required to hold a certain level of risk
# Inputs:
#   - data: dataframe of historical asset prices
#   - target_risk: target level of risk (e.g. 10%)
# Outputs:
#   - capital_required: amount of capital required to hold the target level of risk

calculate_capital_required <- function(data, target_risk) {
  
  # Calculate the returns
  returns <- apply(data, 2, function(x) diff(log(x)))
  
  # Calculate the covariance matrix
  cov_mat <- cov(returns)
  
  # Calculate the portfolio risk
  port_var <- t(c(rep(1, ncol(data)))) %*% cov_mat %*% rep(1, ncol(data))
  port_sd <- sqrt(port_var)
  
  # Calculate the capital required
  capital_required <- target_risk / port_sd^2
  
  return(capital_required)
}

# Call the function with example data and a target risk level of 10%
capital_required <- calculate_capital_required(data, 0.1)
#This will return the amount of capital required to hold a portfolio with a risk level of 10%. You can adjust the target risk level as needed.










---
title: "Pair Trading"
author: "H&M"
date: "2023-04-24"
output:
  pdf_document: default
  html_document: default
---

# **Importing/Treating/Plotting Data**

Importing all the necessary libraries

```{r , include=FALSE}
set.seed(123)
library(stochvol)
library(tseries)
library(readr)
library(zoo)
```

We must import data from Yahoo or from CSV files already obtained and rename Variables

# Price Data

```{r setup, include=FALSE}


market_price <- read_csv("E:/AF/IJE/IJE/Projects/Projet_1 ( Risk Measuring )/market-price.csv")
colnames(market_price) <- c('Date','Price')

View(market_price)

```

Its preferable that we use Log function for the Prices for more exactitude

```{r}
prices <- market_price$Price
logprices <- log(prices)
priceplot <- data.frame(as.Date(market_price$Date), market_price$Price)
```

Plotting the different plots that show Prices vs Time

```{r}

plot(priceplot, type = 'l', col = 'blue', lwd = '2', ylab = "", xlab = "",
     main = 'Historical Bitcoin Prices ($)')
plot(logprices, type = 'l', col = 'green', lwd = '2', ylab = "", xlab = "",
     main = 'Historical Bitcoin Prices ($)')
```

# Trade Volume

```{r}
trade_volume <- read_csv("E:/AF/IJE/IJE/Projects/Projet_1 ( Risk Measuring )/trade-volume.csv")
View(trade_volume)
colnames(trade_volume) <- c('Date','Volume')
plot(trade_volume, type = 'l')

```

# Returns

```{r}

returns <- logprices[2:length(logprices)] - logprices[1:(length(logprices)-1)]
plot(returns, type = 'l')
```

```{r}
plot(prices, type = 'l')
```

January 8th, 2012 is an important date in the history of Bitcoin, as it was the date on which the Bitcoin block reward was halved for the first time. This is a significant event in the Bitcoin network's history, as it marked a major milestone in the cryptocurrency's mining process.

```{r}
bitcoin_volume <- trade_volume[547:nrow(trade_volume),]


bitcoin_volume$Date <- as.Date(bitcoin_volume$Date)


plot(bitcoin_volume, type = 'l', main = 'Volume Traded', col = 'blue')
```

The output "log_returns" will be a time series object containing the logarithmic returns for each period

```{r}
bitcoin_prices <- market_price[547:nrow(market_price),]
bitcoin_prices$Date <- as.Date(bitcoin_prices$Date)
View(bitcoin_prices)
plot(bitcoin_prices, type = 'l')
bitcoin_ret <- logret(bitcoin_prices$Price, demean = TRUE)


plot(bitcoin_prices$Date[2:nrow(bitcoin_prices)], bitcoin_ret, type = 'l',
     col = 'purple', main = 'Bitcoin Returns', ylab = "", lwd = '2')
plot(bitcoin_prices$Date[2:nrow(bitcoin_prices)], sqrt(bitcoin_ret^2), type = 'l',
     col = 'brown', main = 'Bitcoin Observed Volatility', ylab = "", lwd = '2')
```

# Testing Stationnarity of the Time Series

ADF is a test to verify the staionnarity of the time series

```{r}


adf.test(bitcoin_ret)$p.value



```

#In adf.test(bitcoin_ret) : p-value smaller than printed p-value P value less the the level of significance 0.0001 meaning that we dont have stationarity

```{r}
PP.test(bitcoin_ret)$p.value 

```

# Stochastic Volatility Estimates

```{r}
res <- svsample(bitcoin_ret, priormu = c(-10, 1), priorphi = c(20,1.5),priorsigma = 0.1) 


summary(res, showlatent = TRUE)

mean_exp_ht_2 <- as.numeric(summary(res, showlatent = TRUE)$latent[,6])

sd_exp_ht_2 <- as.numeric(summary(res, showlatent = TRUE)$latent[,7])

volatility <- sd_exp_ht_2

stoch_vol <- data.frame(bitcoin_prices$Date, volatility)
colnames(stoch_vol) <- c('Date','volatility')

stoch_vol$volatility <- stoch_vol$vol
stoch_vol <- stoch_vol[2:nrow(stoch_vol),]

#plotting 

plot(stoch_vol, type = 'l', main = 'Estimated (Median) Stochastic Volatility', col = 'brown',
     lwd = '2')

volplot(res,dates = bitcoin_prices$Date[-1])

plot(res, dates = bitcoin_prices$Date[-1])
plot(res, forecast = 10, dates = bitcoin_prices$Date[-1])
plot(resid(res),bitcoin_ret)


RMSE_stochvol <- sqrt((1/nrow(stoch_vol))*sum(stoch_vol[,2]^2 - (sqrt(bitcoin_ret^2))^2)^2)
print(RMSE_stochvol)
summary(res, showlatent = FALSE)

```

-10 : reflecting a negative decline ()pov, 1 for long tail(high volatility)

# GARCH(1,1) Volatility Estimates using library fGarch

```{r}

bitcoin_returns_zoo <- zoo(bitcoin_ret,order.by = as.Date(stoch_vol$Date))
library(fGarch)
fit = garchFit( ~ garch(1, 1), data = bitcoin_returns_zoo)
garchEstimates <- volatility(fit, type = 'sigma')
predict(fit,1)
plot(bitcoin_prices$Date[-1], garchEstimates, type = 'l', 
     col = 'brown', lwd = "2", main = 'Estimated GARCH(1,1) Volatility')

```

# Bitcoin Volatility vs GARCH volatility vs Observed Volatility

```{r}

plot(stoch_vol, type = 'l', col = 'black', lwd = "2", ylim = range(0,1),
     main = 'Comparing Volatility Estimates')
par(new = TRUE)
plot(garchEstimates, type = 'l', col = 'red', lwd = "2",                                #The resulting garchEstimates object is a time series of conditional volatilities for each period in the original time series
     ylim = range(0,1), axes = FALSE, xlab = "", ylab = "")
par(new = TRUE)
plot(sqrt(bitcoin_ret^2), type = 'l', col = 'blue', lwd = "1",
     ylim = range(0,1), axes = FALSE, xlab = "", ylab = "")
legend('topright', c('SV', 'GARCH','Observed'), lty = c(1,1,1),
       lwd = c(2,2,1), col = c('black', 'red', 'blue'))
#########################################################


```

# Rolling Window GARCH Volatility Estimation

```{r}

w <- 100 # window size set to ~ 10% of the data size
rollingWindowGarch <- garchEstimates[1:w]
fit_w <- garchFit( ~ garch(1, 1), data = bitcoin_returns_zoo[1:w])
for(i in (w+1):length(garchEstimates)){
  fit_w <- garchFit( ~ garch(1, 1), data = bitcoin_returns_zoo[(i-(w-1)):i])
  rollingWindowGarch <- append(rollingWindowGarch, 
                               as.numeric(predict(fit_w,1)[3]))
}

plot(bitcoin_prices$Date[-1], garchEstimates, type = 'l', 
     col = 'brown', lwd = "2", 
     main = 'Comparing Rolling Window and Plain Vanilla GARCH Volatilities')
par(new = TRUE)
plot(rollingWindowGarch, type = 'l',
     axes = FALSE, xlab = "", ylab = "",
     col = 'black', lty = 2, lwd = 2)
legend('topright', c('GARCH', 'RW-GARCH'), lty = c(1,2),
       lwd = c(2,2), col = c('brown', 'black'))
#########################################################

```

# RMSE of the 3 Models to quantify the difference between

```{r}

#the actual data and the predicted values from the model.
RMSE_garch <- sqrt((1/nrow(stoch_vol))*sum(garchEstimates^2 - (sqrt(bitcoin_ret^2))^2)^2)
RMSE_stochvol <- sqrt((1/nrow(stoch_vol))*sum(stoch_vol[,2]^2 - (sqrt(bitcoin_ret^2))^2)^2)
RMSE_RWgarch <- sqrt((1/nrow(stoch_vol))*sum(rollingWindowGarch^2 - (sqrt(bitcoin_ret^2))^2)^2)
print(RMSE_garch)
print(RMSE_stochvol)
print(RMSE_RWgarch)
```

*GARCH Model is superior \>\>\>\> ;)*

The Difference between the actual volatility of the data and the predicted volatility from the model, a low rmse indicates that the model is doing a good job of capturing the volatilty dyanamics in the data.
